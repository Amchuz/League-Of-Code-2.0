{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'turicreate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cfe33d26dbcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mturicreate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Setup done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'turicreate'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import turicreate\n",
    "%matplotlib inline\n",
    "print(\"Setup done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('/home/cs/Downloads/bank-full.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can add all the data_visualization functions here, and invoke the function in main()\n",
    "def data_visualization(dataframe):\n",
    "    \n",
    "    # basic data analysis\n",
    "    print('The shape of dataset in terms of rows and cols:\\n', dataframe.shape)\n",
    "    print('*'*100)\n",
    "    print('Have a look at first 10 rows of the dataset: \\n\\n', dataframe.head(10))\n",
    "    print('*'*100)\n",
    "    print('Description about the dataset: \\n\\n', dataframe.describe())\n",
    "    print('*'*100)\n",
    "    print('Description about the dataset including the Categorical variables: \\n\\n', dataframe.describe(include = 'all'))\n",
    "    print('*'*100)\n",
    "    print('Dataset info: \\n\\n',dataframe.info())\n",
    "    print('*'*100)\n",
    "    print('Lets see the what are the output values wrt thier count: \\n\\n', dataframe['SUBSCRIBED'].value_counts())\n",
    "    print('*'*100)\n",
    "    \n",
    "    # univariate analysis\n",
    "    sf = turicreate.SFrame(dataframe)\n",
    "    print(sf.show())\n",
    "    print(sf.plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(bank):\n",
    "    bank=bank.drop_duplicates()\n",
    "    print(\"Duplicates are dropped if any\")\n",
    "    missing = bank.isnull().any().any()\n",
    "    if missing == False:\n",
    "        print(\"no missing values\")\n",
    "    else:\n",
    "        print(\"missing values to be treated\")\n",
    "    bank.columns = [x.upper() for x in data.columns]\n",
    "    data = data.rename(columns = {'MARITAL': 'MARITAL_STATUS','DEFAULT': 'CREDIT', 'PDAYS':'CONTACTED_BEFORE',\n",
    "                                    'PREVIOUS':'PREVIOUS_CAMPAIGN', 'POUTCOME':'PREVIOUS_CAMPAIGN_OUTCOME', 'Y':'SUBSCRIBED'})\n",
    "    list1=['JOB','MARITAL_STATUS','EDUCATION','CREDIT','HOUSING','LOAN','CONTACT','MONTH','PREVIOUS_CAMPAIGN_OUTCOME','SUBSCRIBED']\n",
    "    for l in list1:\n",
    "        sns.countplot(y=l, data=bank, order = bank[l].value_counts().index)\n",
    "        plt.show()\n",
    "    bank.hist(figsize=(10,10), xrot=-45)\n",
    "    plt.show()\n",
    "    sns.heatmap(bank.isnull())\n",
    "    bank.isnull().sum()\n",
    "    print(bank.isnull().values.any())\n",
    "    if data['CONTACTED_BEFORE'].max() <= 999:\n",
    "        print('')\n",
    "    else:\n",
    "        data = data.drop(data[data['CONTACTED_BEFORE'].max() > 999].index)\n",
    "    bank = bank[bank.JOB != 'unknown']\n",
    "    bank = bank[bank.MARITAL_STATUS != 'unknown']\n",
    "    bank = bank[bank.EDUCATION != 'unknown']\n",
    "    del bank['DURATION']\n",
    "    del bank['CONTACT']\n",
    "    bank.info()\n",
    "    bank[\"MONTH\"].replace({\"jan\": 1,\"feb\": 2,\"mar\": 3,\"apr\": 4, \"may\": 5, \"jun\": 6,\"jul\": 7,\"aug\": 8,\"sep\": 9,\"oct\": 10,\"nov\": 11,\"dec\": 12,}, inplace=True)\n",
    "    bank.head(20)\n",
    "    sns.boxplot(x=bank['BALANCE'])\n",
    "    bank[['BALANCE']].mean()\n",
    "    bank['outliers'] = zscore(bank['BALANCE'])\n",
    "    check = (bank['outliers']>3) | (bank['outliers']<-3 )\n",
    "    bank = bank.drop(bank[check].index, axis = 0, inplace = False)\n",
    "    bank = bank.drop('outliers', axis=1)\n",
    "    sns.boxplot(x=bank['BALANCE'])\n",
    "    bank.JOB.replace(['retired', 'unemployed'], 'no_active_income', inplace=True)\n",
    "    bank.MARITAL_STATUS.replace(['single', 'divorced'], 'single', inplace=True)\n",
    "    list1=['JOB','MARITAL_STATUS','EDUCATION','HOUSING','LOAN','MONTH','PREVIOUS_CAMPAIGN_OUTCOME','SUBSCRIBED']\n",
    "    for l in list1:\n",
    "        sns.countplot(y=l, data=bank, order = bank[l].value_counts().index)\n",
    "        plt.show()\n",
    "    bank.JOB.replace(['entrepreneur', 'self-employed'], 'self-employed', inplace=True)\n",
    "    bank.JOB.replace(['admin.', 'management'], 'admini_management', inplace=True)\n",
    "    bank.JOB.replace(['blue-collar', 'technician'], 'blue-collar', inplace=True)\n",
    "    bank.to_csv('cleaned_data.csv',index=False)\n",
    "    data_visualization(bank)\n",
    "    return bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(dataframe):\n",
    "    method = int(input(' 1. Filter Method  2. Wrapper Method 3. Embedded Method \\n Enter the  feature Selection Method :'))\n",
    "    if method == 1:\n",
    "        my_features = do_filter_method(dataframe)\n",
    "    elif method == 2:\n",
    "        my_features = do_wrapper_method(dataframe)\n",
    "    elif method == 3:\n",
    "        my_features = do_embedded_method(dataframe)\n",
    "    \n",
    "    x = dataframe.drop(['SUBSCRIBED'], axis = 1)    \n",
    "    y = dataframe['SUBSCRIBED']\n",
    "    print('All independent features shape:', x.shape)\n",
    "    print('Dependent features shpae:', y.shape)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 0, test_size = 0.2)\n",
    "    s=(train_X.dtypes==\"object\")\n",
    "    object_cols_X=list(s[s].index)\n",
    "    print(object_cols_X)\n",
    "    label_X_train=train_x.copy()\n",
    "    label_X_test=test_x.copy()\n",
    "    label_encoder=LabelEncoder()\n",
    "    for col in object_cols_X:\n",
    "        label_X_train[col]=label_encoder.fit_transform(train_X[col])\n",
    "        label_X_test[col]=label_encoder.transform(test_X[col])\n",
    "    print(\"Done\")\n",
    "    sc = StandardScaler()                                    # scale the data\n",
    "    label_X_train = sc.fit_transform(x_train)\n",
    "    label_X_test = sc.transform(x_test)\n",
    "    c=np.sqrt(label_X_train.shape[0])\n",
    "    print(c)\n",
    "    label_y_train=train_y.copy()\n",
    "    label_y_test=test_y.copy()\n",
    "    print('x_train shape:', label_X_train.shape)\n",
    "    print('y_train shape:', label_Y_train.shape)\n",
    "    print('x_test shape:', label_X_test.shape)\n",
    "    print('y_test shape:', label_Y_test.shape)\n",
    "    print(label_X_train.dtypes)\n",
    "    return label_X_train, label_Y_train, label_X_test, label_Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, y_train):\n",
    "    print('Training \\n', '-'*120)\n",
    "    #print(dataframe.shape)\n",
    "    \n",
    "\n",
    "    print('*'*45, 'Algorithms', '*'*45, '\\n 1. Logistic Regression \\n 2. KNN \\n 3. SVM \\n 4. Decision Tress \\n 5. Random Forests')\n",
    "    algo = int(input(\"Choose the algorithm's respective no: \"))\n",
    "    if algo == 1:\n",
    "      #Logistic_Regression_model(x_train, y_train)\n",
    "        lr = LogisticRegression()\n",
    "        lr.fit(x_train, y_train)\n",
    "        print('Successfully trained the model using LogisticRegression')\n",
    "        return lr\n",
    "\n",
    "    elif algo == 2:          \n",
    "      #KNeighbors_Classifer_model(x_train, y_train, k)\n",
    "        k = int(np.sqrt(x_train.shape[0]))\n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        knn.fit(x_train, y_train)\n",
    "        print('Successfully trained the model using KNN')\n",
    "        return knn\n",
    "            \n",
    "    elif algo == 3:\n",
    "      #Support_Vector_Classifier_model(x_train, y_train)\n",
    "        svm = SVC(kernel = 'linear')   \n",
    "        svm.fit(x_train, y_train)\n",
    "        print('Successfully trained the model using SVM')\n",
    "        return svm\n",
    "\n",
    "    elif algo == 4:\n",
    "      #Decision_Tree_Classifier_model(x_train, y_train, depth, features, samples)\n",
    "        dtree = DecisionTreeClassifier(max_depth = 3)\n",
    "        dtree.fit(x_train, y_train)\n",
    "        print('Successfully trained the model using Decision trees')\n",
    "        return dtree\n",
    "\n",
    "    elif algo == 5:\n",
    "       #Random_Forest_Classifier_model(x_train, y_train, estimators, jobs, features, samples)\n",
    "        rfc = RandomForestClassifier()\n",
    "        rfc.fit(x_train, y_train)\n",
    "        print('Successfully trained the model using Random forest')\n",
    "        return rfc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, x_test):\n",
    "    print('This is TASK 3 \\n', '-'*120)\n",
    "    predictions = model.predict(x_test)\n",
    "    # y_test  actual labels\n",
    "    if model == lr:\n",
    "         print('Model used: Logistic Regression')\n",
    "    elif model == knn:\n",
    "         print('Model used: Logistic Regression')\n",
    "    elif model == svm:\n",
    "         print('Model used: Support Vector Machine')\n",
    "    elif model == dtree:\n",
    "         print('Model used: Descison Trees')\n",
    "    elif model == svm:\n",
    "         print('Model used: Random Forests')\n",
    "\n",
    "    print('The accuracy score for the model used is:', accuracy(y_test, predictions))\n",
    "    print('Confusion matrix:', confusion_matrix(y_test, predictions, labels = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataframe = pd._read_csv(\"bank-full.csv\")\n",
    "    data_visualization(data)\n",
    "    data=cleaning(data)\n",
    "    x_train, y_train, x_test, y_test=pre_processing(data)\n",
    "    model=train(x_train, y_train)\n",
    "    test(model, x_test)\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
